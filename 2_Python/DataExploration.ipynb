{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration, Visualization, and Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data scientists want to know characteristics of their data. This notebook will cover how to explore a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--The pandas package is used to explore datasets. \n",
    "--The numpy package is used for high level mathematical functions. \n",
    "--The matplotlib package is used for visualization (graphs). \n",
    "--The seaborn package makes graphs more beautiful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT PACKAGES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visually Displaying your Data w/ Plots and Graphs\n",
    "## Line graph, histogram, scatter plot, bar graph, pi chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Line Chart w/ Matplotlib (plt)**\n",
    "Create two lists, x and y. Plot and label a line chart with x and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1,2,3,4,5,6,7,8,9,10]\n",
    "y = [0.3,4/5,5,5.5,6,8,12,17,27,30]\n",
    "plt.plot(x,y)\n",
    "plt.title(\"Hey, This is How You Make a Title\")\n",
    "plt.xlabel(\"x values\")\n",
    "plt.ylabel(\"y values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Histogram with Matplotlib (plt)**\n",
    "Create two variables: **N_points** and **n_bins**\n",
    "- N_points will be referenced in as the x variable in the plot.\n",
    "- n_bins reprsents the number of buckets we will use in the histogram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE HISTOGRAM\n",
    "N_points = 100000\n",
    "n_bins = 10\n",
    "\n",
    "# Generate a normal distribution, center at x=0 and y=5\n",
    "x = np.random.randn(N_points)\n",
    "y = .4 * x + np.random.randn(100000) + 5\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
    "\n",
    "# We can set the number of bins with the `bins` kwarg\n",
    "axs[0].hist(x, bins=n_bins)\n",
    "axs[1].hist(y, bins=n_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scatter Plot with Matplotlib (plt)**\n",
    "Create 3 sets for variables: g1, g2 and g3 then combine the three sets in **data**. \n",
    "\n",
    "The for loop assigns a color and a group to each feature in **data**\n",
    "**ax.scatter**() creates the scatterplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE SCATTER PLOT\n",
    "# Create data\n",
    "N = 60\n",
    "g1 = (0.6 + 0.6 * np.random.rand(N), np.random.rand(N))\n",
    "g2 = (0.4+0.3 * np.random.rand(N), 0.5*np.random.rand(N))\n",
    "g3 = (0.3*np.random.rand(N),0.3*np.random.rand(N))\n",
    "\n",
    "data = (g1, g2, g3)\n",
    "colors = (\"red\", \"green\", \"blue\")\n",
    "groups = (\"coffee\", \"tea\", \"water\")\n",
    "\n",
    "# Create plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1, facecolor=\"1.0\")\n",
    "\n",
    "for data, color, group in zip(data, colors, groups):\n",
    "    x, y = data\n",
    "ax.scatter(x, y, alpha=0.8, c=color, edgecolors='none', s=30, label=group)\n",
    "\n",
    "plt.title('Matplot scatter plot')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bar Plot with Matplotlib (plt)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE BAR PLOT\n",
    "labels = ['G1', 'G2', 'G3', 'G4', 'G5']\n",
    "men_means = [20, 34, 30, 35, 27]\n",
    "women_means = [25, 32, 34, 20, 25]\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, men_means, width, label='Men')\n",
    "rects2 = ax.bar(x + width/2, women_means, width, label='Women')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Scores by group and gender')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pie Chart with Matplotlib (plt)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to plot\n",
    "labels = 'Python', 'C++', 'Ruby', 'Java'\n",
    "sizes = [215, 130, 245, 210]\n",
    "colors = ['gold', 'yellowgreen', 'lightcoral', 'lightskyblue']\n",
    "explode = (0.1, 0, 0, 0)  # explode 1st slice\n",
    "\n",
    "# Plot\n",
    "plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n",
    "autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOUSING PRICES DATASET\n",
    "We will use the housing prices dataset to start practicing techniques for viewing and analyzing datasets with Pandas.\n",
    "\n",
    "The housing prices dataset is sourced from Kaggle: https://www.kaggle.com/c/house-prices-advanced-regression-techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPEN DATASET\n",
    "df = pd.read_csv(\"housing_price.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIEW TOP 10 ROWS OF THE DATASET\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape shows (#rows, #columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Review all of the Features in the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the types of integers**\n",
    "- int64: integer\n",
    "- object: Text or mixed numeric and non-numeric values\n",
    "- float: Floating point numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Review Summary Statistics of the Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Review Percent of Missing Values from the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERCENT OF MISSING VALUES\n",
    "total = df.isnull().sum().sort_values(ascending=False)\n",
    "percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selecting Specific Features**\n",
    "\n",
    "Look into the Alley feature to review some of the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[['Alley']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.Alley.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review Correlations of the Features\n",
    "- Create a correlation matrix using corr()\n",
    "- Plot a heatmap of the correlation matrix using seaborn (sns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRELATION PLOT\n",
    "corrmat = df.corr()\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corrmat, vmax=1, square=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order the variables in order of correlation\n",
    "k = 20 #number of variables for heatmap\n",
    "cols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\n",
    "f, ax = plt.subplots(figsize=(14, 10))\n",
    "sns.heatmap(df[cols].corr(), vmax=.8, square=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Pairplot to review feature relationships\n",
    "The feature that we are trying to predict is **SalePrice**\n",
    "\n",
    "These plots will help us review the relationship of SalePrice with two strongly correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['SalePrice', 'OverallQual', 'GrLivArea']\n",
    "sns.pairplot(df[cols], height = 4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review Summary Statistics of the SalePrice feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SalePrice'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review distribution of the SalePrice feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['SalePrice']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the skewness of the SalePrice feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Skewness: %f\" % df['SalePrice'].skew())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'GrLivArea'\n",
    "data = pd.concat([df['SalePrice'], df[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'TotalBsmtSF'\n",
    "data = pd.concat([df['SalePrice'], df[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5     397\n",
       "6     374\n",
       "7     319\n",
       "8     168\n",
       "4     116\n",
       "9      43\n",
       "3      20\n",
       "10     18\n",
       "2       3\n",
       "1       2\n",
       "Name: OverallQual, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Review the number of houses in each OverallQual rating group\n",
    "df['OverallQual'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'OverallQual'\n",
    "data = pd.concat([df['SalePrice'], df[var]], axis=1)\n",
    "f, ax = plt.subplots(figsize=(14, 8))\n",
    "fig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\n",
    "fig.axis(ymin=0, ymax=800000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'YearBuilt'\n",
    "data = pd.concat([df['SalePrice'], df[var]], axis=1)\n",
    "f, ax = plt.subplots(figsize=(16, 8))\n",
    "fig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\n",
    "fig.axis(ymin=0, ymax=800000);\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary\n",
    "Stories aside, we can conclude that:\n",
    "\n",
    "'GrLivArea' and 'TotalBsmtSF' seem to be linearly related with 'SalePrice'. Both relationships are positive, which means that as one variable increases, the other also increases. In the case of 'TotalBsmtSF', we can see that the slope of the linear relationship is particularly high.\n",
    "'OverallQual' and 'YearBuilt' also seem to be related with 'SalePrice'. The relationship seems to be stronger in the case of 'OverallQual', where the box plot shows how sales prices increase with the overall quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MISSING DATA\n",
    "How do data scientists deal with missing values? There are a few ways to tackle this problem.\n",
    "\n",
    "First, **how much data is missing**? It is not wise to work with data where over 30% of the data is missing. However, we do not always have a choice. Discretion should be used for each project. \n",
    "\n",
    "If your data is quantitative, one way is to fill in the missing values with middle-type values: **mean or median**. If it is categorical, you can fill in the missing values to keep the same proportions. \n",
    "\n",
    "More advanced methods of imputation include: clustering and MICE. We will cover general clustering concepts in the next bootcamp! \n",
    "\n",
    "Another way is to simply ignore those data points. Take precaution and try to understand any bias that may come from this method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filling in Missing Data within the Housing Prices Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Review the missing data\n",
    "missing_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPUTE WITH MODE\n",
    "for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond','MSSubClass','SaleType','GarageYrBlt','MSZoning','Electrical','KitchenQual','BsmtQual','Exterior1st','Exterior2nd', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', \"MasVnrType\", \"FireplaceQu\"):\n",
    "    df[col] = df.groupby(\"Neighborhood\")[col].transform(lambda x: x.fillna(x.mode()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPUTE WITH NONE\n",
    "for col in (\"Alley\",\"MiscFeature\",\"PoolQC\",'Fence'):\n",
    "    df[col] = df[col].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPUTE WITH MEDIAN\n",
    "for col in (\"MasVnrArea\", 'LotFrontage','GarageArea', 'GarageCars','BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n",
    "    df[col] = df.groupby(\"Neighborhood\")[col].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROP DATA\n",
    "df = df.drop(['Utilities'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL IN WITH CERTAIN VALUE\n",
    "df[\"Functional\"] = df[\"Functional\"].fillna(\"Typ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Missing Ratio]\n",
       "Index: []"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check remaining missing values if any\n",
    "\n",
    "df_na = (df.isnull().sum() / len(df)) * 100\n",
    "df_na = df_na.drop(df_na[df_na == 0].index).sort_values(ascending=False)\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :df_na})\n",
    "missing_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LINEAR REGRESSION\n",
    "To learn about linear regression: https://www.kdnuggets.com/2019/03/beginners-guide-linear-regression-python-scikit-learn.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the X & Y Variables\n",
    "X = df['SalePrice'].values.reshape(-1,1)\n",
    "y = df['GrLivArea'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the training a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()  \n",
    "regressor.fit(X_train, y_train) #training the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To retrieve the intercept:\n",
    "print(regressor.intercept_)\n",
    "\n",
    "#For retrieving the slope:\n",
    "print(regressor.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Actual': y_test.flatten(), 'Predicted': y_pred.flatten()})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the residuals\n",
    "plt.scatter(X_test, y_test,  color='gray')\n",
    "plt.plot(X_test, y_pred, color='red', linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
